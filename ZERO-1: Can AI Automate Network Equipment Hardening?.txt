ZERO-1: Can AI Automate Network Equipment Hardening?

Introduction: Why is Hardening Still Manual?

If you have ever been involved in a security audit of network infrastructure, you know this process from the inside: thousands of lines of Cisco, Juniper configurations, checks against DISA STIG, CIS Benchmarks. Months of work by a team of highly paid specialists. Errors due to human factors. Lack of technically indisputable evidence of remediation.

Today, I want to talk about a project attempting to transition this process from manual to fully autonomous. This is not just another configuration analyzer—it's a system that autonomously finds vulnerabilities, proves them through exploitation, generates and applies patches, and then provides a cryptographically verifiable report.

The Essence of the Project: One Loop, Full Cycle

Project ZERO-1 is conceived as a prototype demonstrating the possibility of automation through a closed-loop, co-evolutionary hardening process. The MVP focuses on one specific Cisco IOS XE vulnerability, but the architecture is designed with scalability in mind.

What the system does in one cycle:

    Discovery — Autonomous analysis of configuration compliance against DISA STIG.

    Exploitation — Automatic verification of vulnerability exploitability.

    Remediation Synthesis — Generation of a correct configuration patch.

    Verification — Application of the patch and re-testing.

    Evidence Generation — Creation of a cryptographically verifiable report.

The key difference from existing solutions: the system does not merely parse configurations but actively proves vulnerabilities by simulating attacks and autonomously generates fixes.

Choosing the Target Vulnerability for the MVP

For the first prototype, we chose a classic—violation of DISA STIG ID V-220668: "The Cisco switch must not have the default VLAN assigned to any host-facing access ports."

Why this specific vulnerability?

    Clear identification via show run interface and show vlan.

    Simplicity of exploitation (testing connectivity in VLAN 1).

    Unambiguous remediation (moving the port to a non-default VLAN).

    High prevalence in real-world audits.

Architecture: Modular Approach with AI at the Core

The system is built around a central controller orchestrating the cycle execution. Here are the key components:

    Attack Analyst

        Task: SSH session to the switch, data collection, analysis for violation of V-220668.

        Tools: Netmiko for collection, TextFSM for parsing.

        AI Core: Fine-tuned Llama-3.1-8B-Instruct with a dataset of 5000+ examples.

        Output: Structured JSON with findings and an attack plan.

    Attack Executor

        Task: Execution of the attack plan (e.g., ping to a host in VLAN 1).

        Implementation: Python + Paramiko, command execution on an attack host in EVE-NG.

        Output: Report on exploitation success.

    Remediation Synthesizer

        Task: Generation of IOS commands to remediate the vulnerability.

        AI Core: Fine-tuned CodeLlama-13B-Instruct (3000+ examples).

        Example Output: interface Gi2, switchport access vlan 100

        Validation: Syntax check via dry-run.

    Remediation Applier

        Task: Safe application of the patch with automatic rollback on errors.

        Algorithm: Backup → Application → Verification → Commit.

    Verification & Evidence

        Task: Confirmation of remediation effectiveness and formation of an evidence base.

        Key Technology: Merkle Tree for artifact integrity + digital signature via YubiKey PIV.

Test Environment: Infrastructure as Code

The lab is deployed automatically via Terraform + Ansible:

[Attack Host] — [Cisco CSR1000v] — [Target Server in VLAN 1]

All components are containerized (Docker), managed via a single FastAPI controller. EVE-NG Professional with support for Cisco images is used for network emulation.

Workflow: From Launch to a Signed Report

    Initialization: python zero1_controller.py --target-lab zero1-mvp --stig-id V-220668

    Analysis & Attack: Configuration collection → AI analysis → Attack execution.

    Synthesis & Application: Patch generation → Safe application.

    Verification: Re-attack (should fail).

    Evidence: Building a Merkle Tree, digital signing, report generation.

The entire cycle should be completed within 120 minutes.

Critical Risks and Expert Assessments

The project is ambitious, but there are several points of tension:

    Dependence on AI

        Problem: 5000 examples for fine-tuning may be insufficient. LLM hallucinations in a security context are unacceptable.

        MVP Solution: Strict validation of output against JSON schemas, fallback to rule-based logic.

    Integration Complexity

        Problem: EVE-NG API, custom Terraform providers, hardware token setup.

        Recommendation: Start with a simplified version without LLM, focusing on a single vulnerability.

    Security of the System Itself

        Concerns: Docker socket exposure, key storage, replay attacks for Merkle Tree.

        Important: Security review of the architecture before advancing.

Practical Implementation Recommendations

    Phase 0.5 (60 days):

        Rule-based analyzer instead of LLM.

        Basic verification without a Merkle Tree.

        One vulnerability, simple patch.

    Phase 1 (after Phase 0.5 success):

        LLM integration with strict validation.

        Full cryptographic evidence chain.

        Addition of 5-7 STIG checks.

    Phase 2 (Co-evolution):

        Two AI models (attacking and defending) in a competitive mode.

        Support for Juniper JunOS.

        Productization as SaaS or an "appliance".

Conclusion: Prospects and Realism

Project ZERO-1 is not just another configuration parsing script. It is an attempt to create a system capable of autonomously conducting security audits, proving vulnerabilities, and remediating them with a cryptographically verifiable result.

Strengths:

    Innovative approach to security automation.

    End-to-end traceability and non-repudiation.

    Entrepreneurial level of elaboration.

What Requires Attention:

    Realistic timelines (120-150 days instead of 90).

    Contingency budget (+20%).

    Focus on a simplified first version.

If the team can implement even the simplified version—it will already be a breakthrough in network security automation. The main thing is not to get carried away by complexity but to prove the concept's viability with a minimal viable product.
